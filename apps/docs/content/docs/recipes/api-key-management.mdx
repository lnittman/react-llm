---
title: Secure API Key Management
description: Best practices for handling API keys in different environments
---

# Secure API Key Management

Proper API key management is crucial for security and cost control. This guide covers best practices for different deployment scenarios.

## Development Environment

### Environment Variables

The safest approach for development:

```bash
# .env.local (Next.js)
NEXT_PUBLIC_OPENROUTER_API_KEY=sk-or-v1-development-key

# .env (Vite/Create React App)
VITE_OPENROUTER_API_KEY=sk-or-v1-development-key
REACT_APP_OPENROUTER_API_KEY=sk-or-v1-development-key
```

```javascript
// Access in your code
ReactLLM.init({
  providers: {
    openrouter: process.env.NEXT_PUBLIC_OPENROUTER_API_KEY ||
                process.env.VITE_OPENROUTER_API_KEY ||
                process.env.REACT_APP_OPENROUTER_API_KEY
  }
});
```

### Git Security

Always exclude environment files:

```gitignore
# .gitignore
.env
.env.local
.env.*.local
```

## Production Environment

### ❌ Never Do This

```javascript
// DANGER: Exposed API key in production
ReactLLM.init({
  providers: {
    openrouter: 'sk-or-v1-actual-api-key' // Never hardcode!
  }
});
```

### ✅ Proxy Server Pattern

The most secure approach for production:

```javascript
// Frontend: Use a proxy endpoint
ReactLLM.init({
  providers: {
    proxy: '/api/ai-proxy'
  }
});
```

```javascript
// Backend: Node.js/Express proxy
app.post('/api/ai-proxy', async (req, res) => {
  // Validate user authentication
  if (!req.user) {
    return res.status(401).json({ error: 'Unauthorized' });
  }
  
  // Forward to OpenRouter with server-side key
  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
      'Content-Type': 'application/json',
      'HTTP-Referer': 'https://yourdomain.com',
      'X-Title': 'Your App Name'
    },
    body: JSON.stringify(req.body)
  });
  
  // Stream response back to client
  response.body.pipe(res);
});
```

### Next.js API Route

```typescript
// app/api/ai-proxy/route.ts
import { NextRequest, NextResponse } from 'next/server';

export async function POST(request: NextRequest) {
  // Check authentication
  const session = await getServerSession();
  if (!session) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }
  
  const body = await request.json();
  
  // Add rate limiting
  const rateLimitOk = await checkRateLimit(session.user.id);
  if (!rateLimitOk) {
    return NextResponse.json({ error: 'Rate limit exceeded' }, { status: 429 });
  }
  
  // Forward to OpenRouter
  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(body)
  });
  
  return NextResponse.json(await response.json());
}
```

## Browser Extension Pattern

For browser extensions with better security:

```javascript
// manifest.json
{
  "permissions": ["storage"],
  "host_permissions": ["https://openrouter.ai/*"]
}
```

```javascript
// background.js - Handle API calls
chrome.runtime.onMessage.addListener(async (request, sender, sendResponse) => {
  if (request.type === 'AI_CHAT') {
    // Get key from secure extension storage
    const { apiKey } = await chrome.storage.local.get('apiKey');
    
    if (!apiKey) {
      sendResponse({ error: 'No API key configured' });
      return;
    }
    
    // Make request from background script
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(request.payload)
    });
    
    sendResponse(await response.json());
  }
});
```

## Team & Enterprise Setup

### Shared Development Keys

```javascript
// Team configuration service
class TeamConfigService {
  async getConfig(userId) {
    // Fetch team-specific configuration
    const response = await fetch('/api/team/config', {
      headers: {
        'Authorization': `Bearer ${userToken}`
      }
    });
    
    const config = await response.json();
    
    return {
      providers: {
        proxy: config.aiProxyEndpoint
      },
      allowedModels: config.allowedModels,
      maxTokens: config.maxTokens,
      rateLimit: config.rateLimit
    };
  }
}

// Initialize with team config
const config = await teamConfigService.getConfig(currentUser.id);
ReactLLM.init(config);
```

### Role-Based Access

```javascript
// Server-side middleware
async function aiProxyMiddleware(req, res, next) {
  const user = req.user;
  
  // Check user permissions
  if (!user.permissions.includes('ai_chat')) {
    return res.status(403).json({ error: 'AI chat not enabled for your account' });
  }
  
  // Apply role-based limits
  const limits = {
    admin: { rpm: 100, maxTokens: 4000 },
    developer: { rpm: 50, maxTokens: 2000 },
    viewer: { rpm: 10, maxTokens: 1000 }
  };
  
  req.aiLimits = limits[user.role] || limits.viewer;
  next();
}
```

## Client-Side Key Storage

When you must store keys client-side (development only):

### Secure Browser Storage

```javascript
// Encrypt keys before storing
import { encrypt, decrypt } from './crypto-utils';

class SecureKeyManager {
  constructor() {
    this.storageKey = 'react-llm-keys';
    this.salt = this.getOrCreateSalt();
  }
  
  async saveKey(provider, apiKey) {
    const keys = await this.getKeys();
    keys[provider] = await encrypt(apiKey, this.salt);
    
    // Use IndexedDB for better security than localStorage
    const db = await this.openDB();
    const tx = db.transaction(['keys'], 'readwrite');
    await tx.objectStore('keys').put(keys, this.storageKey);
  }
  
  async getKeys() {
    const db = await this.openDB();
    const keys = await db.transaction(['keys'])
      .objectStore('keys')
      .get(this.storageKey);
    
    const decrypted = {};
    for (const [provider, encryptedKey] of Object.entries(keys || {})) {
      decrypted[provider] = await decrypt(encryptedKey, this.salt);
    }
    
    return decrypted;
  }
  
  async openDB() {
    return await openDB('ReactLLMSecure', 1, {
      upgrade(db) {
        db.createObjectStore('keys');
      }
    });
  }
  
  getOrCreateSalt() {
    let salt = localStorage.getItem('react-llm-salt');
    if (!salt) {
      salt = crypto.randomUUID();
      localStorage.setItem('react-llm-salt', salt);
    }
    return salt;
  }
}
```

## Rate Limiting & Cost Control

### Client-Side Tracking

```javascript
class UsageTracker {
  constructor() {
    this.usage = this.loadUsage();
  }
  
  async trackRequest(model, tokens) {
    const cost = this.calculateCost(model, tokens);
    
    this.usage.requests += 1;
    this.usage.tokens += tokens;
    this.usage.cost += cost;
    this.usage.lastReset = this.usage.lastReset || Date.now();
    
    // Reset daily
    if (Date.now() - this.usage.lastReset > 24 * 60 * 60 * 1000) {
      this.usage = { requests: 0, tokens: 0, cost: 0, lastReset: Date.now() };
    }
    
    this.saveUsage();
    
    // Warn if approaching limits
    if (this.usage.cost > 10) {
      console.warn('Daily AI spend exceeds $10');
    }
  }
  
  calculateCost(model, tokens) {
    const rates = {
      'claude-3-opus': 0.015,
      'gpt-4-turbo': 0.01,
      'claude-3-sonnet': 0.003
    };
    return (tokens / 1000) * (rates[model] || 0.002);
  }
}
```

### Server-Side Protection

```javascript
// Redis-based rate limiting
async function rateLimitMiddleware(req, res, next) {
  const userId = req.user.id;
  const key = `ratelimit:${userId}:${Date.now() / 60000 | 0}`;
  
  const count = await redis.incr(key);
  await redis.expire(key, 60);
  
  if (count > 10) { // 10 requests per minute
    return res.status(429).json({
      error: 'Rate limit exceeded',
      retryAfter: 60
    });
  }
  
  next();
}
```

## Security Checklist

### Development
- ✅ Use environment variables
- ✅ Add .env to .gitignore
- ✅ Use separate development keys
- ✅ Enable key rotation

### Production
- ✅ Never expose keys in client code
- ✅ Implement proxy server
- ✅ Add authentication checks
- ✅ Implement rate limiting
- ✅ Monitor usage and costs
- ✅ Use HTTPS only
- ✅ Validate input data
- ✅ Log security events

### Team/Enterprise
- ✅ Centralized key management
- ✅ Role-based access control
- ✅ Usage analytics
- ✅ Cost allocation
- ✅ Audit trails
- ✅ Compliance controls

## Example: Complete Secure Setup

```javascript
// Secure production configuration
class SecureReactLLM {
  async initialize() {
    // Check environment
    const isProd = process.env.NODE_ENV === 'production';
    
    if (isProd) {
      // Production: Use proxy
      ReactLLM.init({
        providers: {
          proxy: '/api/secure-ai-proxy'
        },
        beforeRequest: async (request) => {
          // Add auth token
          request.headers = {
            ...request.headers,
            'X-Auth-Token': await this.getAuthToken()
          };
          return request;
        },
        onError: (error) => {
          // Log security events
          if (error.status === 401) {
            this.logSecurityEvent('unauthorized_ai_access');
          }
        }
      });
    } else {
      // Development: Use env vars
      ReactLLM.init({
        providers: {
          openrouter: process.env.VITE_OPENROUTER_API_KEY
        },
        debug: {
          logLevel: 'verbose'
        }
      });
    }
  }
  
  async getAuthToken() {
    // Implement your auth logic
    return localStorage.getItem('authToken');
  }
  
  logSecurityEvent(event) {
    // Send to your logging service
    console.error('Security Event:', event);
  }
}

// Usage
const secureAI = new SecureReactLLM();
await secureAI.initialize();
```

Remember: The best API key is one that never reaches the client. Always prefer server-side proxies for production deployments.